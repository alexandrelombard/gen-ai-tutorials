{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T13:18:31.522510Z",
     "start_time": "2024-06-12T13:18:31.512819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math,copy,re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import random"
   ],
   "id": "632aecbcff9480e0",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data\n",
    "\n",
    "Reading the data from the files."
   ],
   "id": "23f4564b8b5f926"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T13:18:31.662293Z",
     "start_time": "2024-06-12T13:18:31.578553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categories = []\n",
    "category_lines = {}\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk('data/names'):\n",
    "    for (i, filename) in enumerate([dirpath + os.sep + f for f in filenames]):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        categories.append(category)\n",
    "        lines = open(filename, encoding='utf-8').read().lower().strip().split('\\n')\n",
    "        category_lines[category] = lines\n",
    "\n",
    "\n",
    "def str_to_tensor(name: str) -> torch.Tensor:\n",
    "    tensor = torch.zeros(len(name), 1, 512)\n",
    "    for (i, c) in enumerate(name):\n",
    "        tensor[i] = F.one_hot(torch.Tensor([ord(c)]).long(), num_classes=512)\n",
    "\n",
    "    return tensor"
   ],
   "id": "b217b7bec984455f",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Neural Network Module\n",
    "\n",
    "Defining the neural network module"
   ],
   "id": "e83a2284920160b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T13:18:31.677668Z",
     "start_time": "2024-06-12T13:18:31.664303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, bias=True):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        \n",
    "        self.ft = nn.Linear(self.input_size + self.hidden_size, self.hidden_size, bias=self.bias)\n",
    "        self.it = nn.Linear(self.input_size + self.hidden_size, self.hidden_size, bias=self.bias)\n",
    "        self.ct = nn.Linear(self.input_size + self.hidden_size, self.hidden_size, bias=self.bias)\n",
    "        self.ot = nn.Linear(self.input_size + self.hidden_size, self.hidden_size, bias=self.bias)\n",
    "        \n",
    "        self.h2o = nn.Linear(self.hidden_size, output_size, bias=self.bias)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, h, c):\n",
    "        x_h = torch.cat((x, h), dim=1)\n",
    "        self.ft(x_h)\n",
    "        forget_gate = F.sigmoid(self.ft(x_h))\n",
    "        input_gate = F.sigmoid(self.it(x_h)) * F.tanh(self.ct(x_h))\n",
    "        cell_state = forget_gate * c + input_gate\n",
    "        hidden_state = F.sigmoid(self.ot(x_h)) * F.tanh(cell_state)\n",
    "        output = self.softmax(self.h2o(hidden_state))\n",
    "        return cell_state, hidden_state, output\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "    def init_cell_state(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 193
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T13:18:31.689804Z",
     "start_time": "2024-06-12T13:18:31.679683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_hidden = 128\n",
    "lstm = LSTMCell(512, n_hidden, len(categories))"
   ],
   "id": "115954d8b808e068",
   "outputs": [],
   "execution_count": 194
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "100156189b6d984a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T13:18:31.695912Z",
     "start_time": "2024-06-12T13:18:31.690816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005\n",
    "n_iters = 100000"
   ],
   "id": "b9b521114bd2e6b8",
   "outputs": [],
   "execution_count": 195
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T13:18:31.703872Z",
     "start_time": "2024-06-12T13:18:31.697923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_training_example():\n",
    "    category = random.choice(list(categories))\n",
    "    line = random.choice(category_lines[category])\n",
    "    category_tensor = torch.tensor([categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = str_to_tensor(line)\n",
    "    return category_tensor, line_tensor"
   ],
   "id": "d0ac929806f28970",
   "outputs": [],
   "execution_count": 196
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T13:18:31.711811Z",
     "start_time": "2024-06-12T13:18:31.705876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(category_tensor, line_tensor):\n",
    "    hidden = lstm.init_hidden()\n",
    "    cell_state = lstm.init_cell_state()\n",
    "    \n",
    "    lstm.zero_grad()\n",
    "    for i in range (line_tensor.size()[0]):\n",
    "        cell_state, hidden, output = lstm(line_tensor[i], hidden, cell_state)\n",
    "        \n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in lstm.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "    return output, loss.item()"
   ],
   "id": "bde54506c9dcfc2e",
   "outputs": [],
   "execution_count": 197
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T13:30:34.617519Z",
     "start_time": "2024-06-12T13:18:31.713814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_loss = 0\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category_tensor, line_tensor = get_training_example()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss"
   ],
   "id": "7de3b63dd6bcc335",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "2716168e82173647"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T13:37:28.190154Z",
     "start_time": "2024-06-12T13:37:28.177576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "line_tensor = str_to_tensor(\"Lombard\")\n",
    "\n",
    "hidden = lstm.init_hidden()\n",
    "cell_state = lstm.init_cell_state()\n",
    "\n",
    "for i in range (line_tensor.size()[0]):\n",
    "    cell_state, hidden, output = lstm(line_tensor[i], hidden, cell_state)\n",
    "        \n",
    "print(categories[output.argmax().item()])"
   ],
   "id": "de0ee8e847945e83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutch\n"
     ]
    }
   ],
   "execution_count": 250
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
