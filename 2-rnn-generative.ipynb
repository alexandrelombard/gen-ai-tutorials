{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\n",
    "\n",
    "The goal is to generate names using the RNN architecture designed in the 1-RNN."
   ],
   "id": "d9967f3f4a8440e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "d3654bab604620c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T12:25:52.388642Z",
     "start_time": "2024-06-14T12:25:52.368577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import typing\n",
    "import string"
   ],
   "id": "fd3005d709a2a2b4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading data",
   "id": "d9e671da25e83314"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:21:54.014172Z",
     "start_time": "2024-06-14T09:21:53.992052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categories = []\n",
    "category_lines = {}\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk('data/names'):\n",
    "    for (i, filename) in enumerate([dirpath + os.sep + f for f in filenames]):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        categories.append(category)\n",
    "        lines = open(filename, encoding='utf-8').read().lower().strip().split('\\n')\n",
    "        category_lines[category] = lines\n",
    "        \n",
    "n_categories = len(category_lines)"
   ],
   "id": "263682020f101611",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:21:54.027704Z",
     "start_time": "2024-06-14T09:21:54.018165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def input_tensor(name: str) -> torch.Tensor:\n",
    "    tensor = torch.zeros(len(name), 1, 512)\n",
    "    for (i, c) in enumerate(name):\n",
    "        tensor[i] = F.one_hot(torch.Tensor([ord(c)]).long(), num_classes=512)\n",
    "        \n",
    "    return tensor"
   ],
   "id": "b280c6f3e4c5e193",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:21:54.039228Z",
     "start_time": "2024-06-14T09:21:54.031236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def category_to_tensor(category: str) -> torch.Tensor:\n",
    "    return F.one_hot(torch.Tensor([categories.index(category)]).long(), num_classes=n_categories)"
   ],
   "id": "6033ad998ed56c4a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:21:54.054487Z",
     "start_time": "2024-06-14T09:21:54.044231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def target_tensor(name: str) -> torch.Tensor:\n",
    "    tensor = torch.zeros(len(name), 1, 512)\n",
    "    for (i, c) in enumerate(name):\n",
    "        if i > 0:\n",
    "            tensor[i - 1] = F.one_hot(torch.Tensor([ord(c)]).long(), num_classes=512)\n",
    "            \n",
    "    tensor[len(name) - 1] = F.one_hot(torch.Tensor([512 - 1]).long(), num_classes=512)\n",
    "    \n",
    "    return tensor"
   ],
   "id": "b20856fcf3d23cd3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Neural network module",
   "id": "fd733342a5874132"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:21:54.079482Z",
     "start_time": "2024-06-14T09:21:54.058487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_categories):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), dim=1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), dim=1)\n",
    "        output = self.softmax(self.dropout(self.o2o(output_combined)))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ],
   "id": "75d64d8e5b694fa6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:21:54.100549Z",
     "start_time": "2024-06-14T09:21:54.081482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_hidden = 128\n",
    "rnn = RNN(512, n_hidden, 512, len(categories))"
   ],
   "id": "ed21e59968315f3c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "e8894f4fcffda363"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:21:54.112088Z",
     "start_time": "2024-06-14T09:21:54.103547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_training_example() -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    category = random.choice(categories)\n",
    "    line = random.choice(category_lines[category])\n",
    "    category_t = category_to_tensor(category)\n",
    "    line_t = input_tensor(line)\n",
    "    target_t = target_tensor(line)\n",
    "    return category_t, line_t, target_t"
   ],
   "id": "df001ebbbda0d41e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:21:54.125881Z",
     "start_time": "2024-06-14T09:21:54.115076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "n_iters = 100000\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(category_tensor, input_tensor, target_tensor):\n",
    "    target_tensor.unsqueeze_(1)\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    loss = torch.Tensor([0])\n",
    "    \n",
    "    for i in range(input_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_tensor[i], hidden)\n",
    "        l = criterion(output, torch.argmax(target_tensor[i].squeeze(0), dim=1))\n",
    "        loss += l\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "    return output, loss.item() / input_tensor.size(0)"
   ],
   "id": "21274db236434b55",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T09:42:05.034109Z",
     "start_time": "2024-06-14T09:21:54.128875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_loss = 0\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category_tensor, line_tensor, target_t = get_training_example()\n",
    "    output, loss = train(category_tensor, line_tensor, target_t)\n",
    "    current_loss += loss"
   ],
   "id": "898351b4a028aa94",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "b74ce2472f9bcefb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T12:30:07.016410Z",
     "start_time": "2024-06-14T12:30:06.932209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate(category, start_letter, max_length=20):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        category_tensor = category_to_tensor(category)\n",
    "        input = input_tensor(start_letter)\n",
    "        hidden = rnn.init_hidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == 512 - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = chr(topi)\n",
    "                output_name += letter\n",
    "            input = input_tensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# Now we can generate a name for a given category\n",
    "for start_letter in range(ord('a'), ord('z') + 1):\n",
    "    print(generate('Polish', chr(start_letter)))"
   ],
   "id": "200e26532c8f3768",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alaka\n",
      "bariski\n",
      "chardak\n",
      "dongak\n",
      "ertowak\n",
      "fariski\n",
      "gariski\n",
      "hanger\n",
      "iroski\n",
      "jander\n",
      "koski\n",
      "lowek\n",
      "marik\n",
      "noski\n",
      "oraka\n",
      "pariski\n",
      "qurak\n",
      "roski\n",
      "sander\n",
      "tangaka\n",
      "uraka\n",
      "vandaka\n",
      "wakis\n",
      "xoski\n",
      "yangak\n",
      "zander\n"
     ]
    }
   ],
   "execution_count": 69
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
