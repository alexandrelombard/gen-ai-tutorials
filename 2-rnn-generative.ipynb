{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\n",
    "\n",
    "The goal is to generate names using the RNN architecture designed in the 1-RNN."
   ],
   "id": "d9967f3f4a8440e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "d3654bab604620c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:55:32.207473Z",
     "start_time": "2024-06-13T14:55:32.195462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import typing"
   ],
   "id": "fd3005d709a2a2b4",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading data",
   "id": "d9e671da25e83314"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:52:49.440299Z",
     "start_time": "2024-06-13T14:52:49.398797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categories = []\n",
    "category_lines = {}\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk('data/names'):\n",
    "    for (i, filename) in enumerate([dirpath + os.sep + f for f in filenames]):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        categories.append(category)\n",
    "        lines = open(filename, encoding='utf-8').read().lower().strip().split('\\n')\n",
    "        category_lines[category] = lines\n",
    "        \n",
    "n_categories = len(category_lines)"
   ],
   "id": "263682020f101611",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:52:49.471029Z",
     "start_time": "2024-06-13T14:52:49.464275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def input_tensor(name: str) -> torch.Tensor:\n",
    "    tensor = torch.zeros(len(name), 1, 512)\n",
    "    for (i, c) in enumerate(name):\n",
    "        tensor[i] = F.one_hot(torch.Tensor([ord(c)]).long(), num_classes=512)\n",
    "        \n",
    "    return tensor"
   ],
   "id": "b280c6f3e4c5e193",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:52:49.534005Z",
     "start_time": "2024-06-13T14:52:49.522644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def category_to_tensor(category: str) -> torch.Tensor:\n",
    "    return F.one_hot(torch.Tensor([categories.index(category)]).long(), num_classes=n_categories)"
   ],
   "id": "6033ad998ed56c4a",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:52:49.682996Z",
     "start_time": "2024-06-13T14:52:49.658795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def target_tensor(name: str) -> torch.Tensor:\n",
    "    tensor = torch.zeros(len(name), 1, 512)\n",
    "    for (i, c) in enumerate(name):\n",
    "        if i > 0:\n",
    "            tensor[i - 1] = F.one_hot(torch.Tensor([ord(c)]).long(), num_classes=512)\n",
    "            \n",
    "    tensor[len(name) - 1] = F.one_hot(torch.Tensor([512 - 1]).long(), num_classes=512)\n",
    "    \n",
    "    return tensor"
   ],
   "id": "b20856fcf3d23cd3",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Neural network module",
   "id": "fd733342a5874132"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:52:49.909209Z",
     "start_time": "2024-06-13T14:52:49.892521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_categories):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), dim=1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), dim=1)\n",
    "        output = self.softmax(self.dropout(self.o2o(output_combined)))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ],
   "id": "75d64d8e5b694fa6",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:52:50.006211Z",
     "start_time": "2024-06-13T14:52:49.979208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_hidden = 128\n",
    "rnn = RNN(512, n_hidden, 512, len(categories))"
   ],
   "id": "ed21e59968315f3c",
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "e8894f4fcffda363"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:56:40.730893Z",
     "start_time": "2024-06-13T14:56:40.717817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_training_example() -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    category = random.choice(categories)\n",
    "    line = random.choice(category_lines[category])\n",
    "    category_t = category_to_tensor(category)\n",
    "    line_t = input_tensor(line)\n",
    "    target_t = target_tensor(line)\n",
    "    return category_t, line_t, target_t"
   ],
   "id": "df001ebbbda0d41e",
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:52:50.136213Z",
     "start_time": "2024-06-13T14:52:50.113209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "n_iters = 100000\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(category_tensor, input_tensor, target_tensor):\n",
    "    target_tensor.unsqueeze_(1)\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    loss = torch.Tensor([0])\n",
    "    \n",
    "    for i in range(input_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor, input_tensor[i], hidden)\n",
    "        l = criterion(output, target_tensor[i].squeeze(0))\n",
    "        loss += l\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "    return output, loss.item() / input_tensor.size(0)"
   ],
   "id": "21274db236434b55",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T14:58:00.718727Z",
     "start_time": "2024-06-13T14:58:00.557739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_loss = 0\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category_tensor, line_tensor, target_t = get_training_example()\n",
    "    output, loss = train(category_tensor, line_tensor, target_t)\n",
    "    current_loss += loss"
   ],
   "id": "898351b4a028aa94",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[179], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28miter\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_iters \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      3\u001B[0m     category_tensor, line_tensor, target_t \u001B[38;5;241m=\u001B[39m get_training_example()\n\u001B[1;32m----> 4\u001B[0m     output, loss \u001B[38;5;241m=\u001B[39m train(category_tensor, line_tensor, target_t)\n\u001B[0;32m      5\u001B[0m     current_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n",
      "Cell \u001B[1;32mIn[145], line 16\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(category_tensor, input_tensor, target_tensor)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(input_tensor\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)):\n\u001B[0;32m     15\u001B[0m     output, hidden \u001B[38;5;241m=\u001B[39m rnn(category_tensor, input_tensor[i], hidden)\n\u001B[1;32m---> 16\u001B[0m     l \u001B[38;5;241m=\u001B[39m criterion(output, target_tensor[i]\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     17\u001B[0m     loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m l\n\u001B[0;32m     19\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:216\u001B[0m, in \u001B[0;36mNLLLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mnll_loss(\u001B[38;5;28minput\u001B[39m, target, weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mignore_index, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2733\u001B[0m, in \u001B[0;36mnll_loss\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001B[0m\n\u001B[0;32m   2731\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2732\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 2733\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mnll_loss_nd(\u001B[38;5;28minput\u001B[39m, target, weight, _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction), ignore_index)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "execution_count": 179
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "b74ce2472f9bcefb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
