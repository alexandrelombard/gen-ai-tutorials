{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The idea is to build a model to take as input a sequence of characters representing a name, and find the associated country.\n",
    "\n",
    "Inspired by: https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial"
   ],
   "id": "9758bfb81e9634f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "68ea9538c6149a85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:04:57.320826Z",
     "start_time": "2024-06-13T15:04:53.940948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data\n",
    "\n",
    "Reading the data from the files."
   ],
   "id": "58442cc196167293"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:05:10.282963Z",
     "start_time": "2024-06-13T15:05:10.265785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categories = []\n",
    "category_lines = {}\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk('data/names'):\n",
    "    for (i, filename) in enumerate([dirpath + os.sep + f for f in filenames]):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        categories.append(category)\n",
    "        lines = open(filename, encoding='utf-8').read().lower().strip().split('\\n')\n",
    "        category_lines[category] = lines"
   ],
   "id": "fd89698efbb16db8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:05:12.496495Z",
     "start_time": "2024-06-13T15:05:12.481722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def str_to_tensor(name: str) -> torch.Tensor:\n",
    "    tensor = torch.zeros(len(name), 1, 512)\n",
    "    for (i, c) in enumerate(name):\n",
    "        tensor[i] = F.one_hot(torch.Tensor([ord(c)]).long(), num_classes=512)\n",
    "        \n",
    "    return tensor"
   ],
   "id": "9958585b107d4f80",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Neural network module",
   "id": "6c9e744f2acb8815"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:05:14.544980Z",
     "start_time": "2024-06-13T15:05:14.528619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ],
   "id": "220db560a77d686",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:05:17.126267Z",
     "start_time": "2024-06-13T15:05:17.110656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_hidden = 128\n",
    "rnn = RNN(512, n_hidden, len(categories))"
   ],
   "id": "16ea4f90454618ca",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "e8dc972d2490dbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:05:19.343625Z",
     "start_time": "2024-06-13T15:05:19.337350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005\n",
    "n_iters = 100000"
   ],
   "id": "aa454cdc04097a1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:05:21.307816Z",
     "start_time": "2024-06-13T15:05:21.297258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_training_example():\n",
    "    category = random.choice(list(categories))\n",
    "    line = random.choice(category_lines[category])\n",
    "    category_tensor = torch.tensor([categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = str_to_tensor(line)\n",
    "    return category_tensor, line_tensor"
   ],
   "id": "47c5baf4e4ff926d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:08:10.413965Z",
     "start_time": "2024-06-13T15:08:10.404933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range (line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "    return output, loss.item()"
   ],
   "id": "f14daad39d261667",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:16:58.604852Z",
     "start_time": "2024-06-13T15:08:12.807016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_loss = 0\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category_tensor, line_tensor = get_training_example()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss"
   ],
   "id": "bb4ba261ff84b11d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation of results",
   "id": "ea6e1be6662271bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "line_tensor = str_to_tensor(\"satoshi\")\n",
    "\n",
    "hidden = rnn.init_hidden()\n",
    "\n",
    "for i in range (line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "print(categories[output.argmax().item()])"
   ],
   "id": "a814470a8ccee753",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
