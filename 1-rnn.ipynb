{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9758bfb81e9634f6",
   "metadata": {},
   "source": [
    "The idea is to build a model to take as input a sequence of characters representing a name, and find the associated country.\n",
    "\n",
    "Inspired by: https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea9538c6149a85",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:06:50.726035Z",
     "start_time": "2024-06-18T09:06:50.721586Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import unicodedata\n",
    "import string"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "58442cc196167293",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Reading the data from the files."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:06:52.421074Z",
     "start_time": "2024-06-18T09:06:52.414992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n"
   ],
   "id": "dcb9b4a2f0acba35",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "fd89698efbb16db8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:07:24.997944Z",
     "start_time": "2024-06-18T09:07:24.862428Z"
    }
   },
   "source": [
    "categories = []\n",
    "category_lines = {}\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk('data/names'):\n",
    "    for (i, filename) in enumerate([dirpath + os.sep + f for f in filenames]):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        categories.append(category)\n",
    "        lines = open(filename, encoding='utf-8').read().lower().strip().split('\\n')\n",
    "        category_lines[category] = [unicode_to_ascii(line) for line in lines]"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "9958585b107d4f80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:08:41.218115Z",
     "start_time": "2024-06-18T09:08:41.208118Z"
    }
   },
   "source": [
    "def str_to_tensor(name: str) -> torch.Tensor:\n",
    "    tensor = torch.zeros(len(name), 1, n_letters)\n",
    "    for (i, c) in enumerate(name):\n",
    "        tensor[i] = F.one_hot(torch.Tensor([ord(c)]).long(), num_classes=n_letters)\n",
    "        \n",
    "    return tensor"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "6c9e744f2acb8815",
   "metadata": {},
   "source": [
    "# Neural network module"
   ]
  },
  {
   "cell_type": "code",
   "id": "220db560a77d686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:08:47.133021Z",
     "start_time": "2024-06-18T09:08:47.125260Z"
    }
   },
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "16ea4f90454618ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:08:49.186267Z",
     "start_time": "2024-06-18T09:08:49.179858Z"
    }
   },
   "source": [
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, len(categories))"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "e8dc972d2490dbe",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "id": "aa454cdc04097a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:08:51.251742Z",
     "start_time": "2024-06-18T09:08:51.247315Z"
    }
   },
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005\n",
    "n_iters = 100000"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "47c5baf4e4ff926d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:08:52.810323Z",
     "start_time": "2024-06-18T09:08:52.805027Z"
    }
   },
   "source": [
    "def get_training_example():\n",
    "    category = random.choice(list(categories))\n",
    "    line = random.choice(category_lines[category])\n",
    "    category_tensor = torch.tensor([categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = str_to_tensor(line)\n",
    "    return category_tensor, line_tensor"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "f14daad39d261667",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:08:54.560204Z",
     "start_time": "2024-06-18T09:08:54.553080Z"
    }
   },
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    rnn.zero_grad()\n",
    "    \n",
    "    for i in range (line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    # optimizer.step()\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "    return output, loss.item()"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "bb4ba261ff84b11d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T09:08:56.517394Z",
     "start_time": "2024-06-18T09:08:56.463052Z"
    }
   },
   "source": [
    "all_losses = []\n",
    "current_loss = 0\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category_tensor, line_tensor = get_training_example()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    if iter % 100 == 0:\n",
    "        print(iter, \":\", torch.Tensor(all_losses[-100:]).mean())\n",
    "        all_losses.append(loss)\n",
    "    current_loss += loss"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Class values must be smaller than num_classes.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[42], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m current_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28miter\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_iters \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m----> 4\u001B[0m     category_tensor, line_tensor \u001B[38;5;241m=\u001B[39m get_training_example()\n\u001B[0;32m      5\u001B[0m     output, loss \u001B[38;5;241m=\u001B[39m train(category_tensor, line_tensor)\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28miter\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[1;32mIn[40], line 5\u001B[0m, in \u001B[0;36mget_training_example\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m line \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39mchoice(category_lines[category])\n\u001B[0;32m      4\u001B[0m category_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([categories\u001B[38;5;241m.\u001B[39mindex(category)], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[1;32m----> 5\u001B[0m line_tensor \u001B[38;5;241m=\u001B[39m str_to_tensor(line)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m category_tensor, line_tensor\n",
      "Cell \u001B[1;32mIn[36], line 4\u001B[0m, in \u001B[0;36mstr_to_tensor\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m      2\u001B[0m tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mlen\u001B[39m(name), \u001B[38;5;241m1\u001B[39m, n_letters)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (i, c) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(name):\n\u001B[1;32m----> 4\u001B[0m     tensor[i] \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mone_hot(torch\u001B[38;5;241m.\u001B[39mTensor([\u001B[38;5;28mord\u001B[39m(c)])\u001B[38;5;241m.\u001B[39mlong(), num_classes\u001B[38;5;241m=\u001B[39mn_letters)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tensor\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Class values must be smaller than num_classes."
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "c5b8b136587bbeec",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-18T08:52:01.284398Z"
    }
   },
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure()\n\u001B[1;32m----> 2\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(all_losses)\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'all_losses' is not defined"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ea6e1be6662271bf",
   "metadata": {},
   "source": [
    "# Evaluation of results"
   ]
  },
  {
   "cell_type": "code",
   "id": "a814470a8ccee753",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "line_tensor = str_to_tensor(\"lombardo\")\n",
    "\n",
    "hidden = rnn.init_hidden()\n",
    "\n",
    "for i in range (line_tensor.size()[0]):\n",
    "    output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "print(categories[output.argmax().item()])"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
